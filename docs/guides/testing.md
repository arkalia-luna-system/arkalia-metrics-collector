# ğŸ§ª Guide des Tests

**Tests complets et validation pour Arkalia Metrics Collector**

## ğŸ“Š **Vue d'ensemble des Tests**

Arkalia Metrics Collector dispose d'une suite de tests complÃ¨te avec **110 tests** couvrant tous les aspects du systÃ¨me :

- âœ… **Tests unitaires** : FonctionnalitÃ©s individuelles
- âœ… **Tests d'intÃ©gration** : Projets externes et validation
- âœ… **Tests de performance** : Mesures de vitesse et mÃ©moire
- âœ… **Tests CLI** : Interface en ligne de commande

## ğŸ¯ **Types de Tests**

### 1. **Tests Unitaires** (`tests/unit/`)

#### Collecteurs (`test_metrics_collector.py`)
- Initialisation et configuration
- Collecte des mÃ©triques Python
- Collecte des tests avec pytest
- Collecte de la documentation
- Gestion des exclusions (venv, cache, etc.)
- Tests de performance sur gros projets

#### Exporteurs (`test_metrics_exporter.py`)
- Export JSON, Markdown, HTML, CSV
- Validation du contenu des exports
- Gestion des erreurs d'export
- CrÃ©ation automatique des dossiers
- Tests avec gros volumes de donnÃ©es

#### Validateurs (`test_metrics_validator.py`)
- Validation de la structure des mÃ©triques
- Validation de cohÃ©rence des donnÃ©es
- Validation de qualitÃ© (couverture, etc.)
- Messages d'erreur et d'avertissement
- Tests de performance sur gros datasets

#### CLI (`test_cli_main.py`)
- Commandes `collect`, `validate`, `serve`
- Options et arguments
- Gestion des erreurs
- Validation des outputs
- Tests avec chemins spÃ©ciaux

### 2. **Tests d'IntÃ©gration** (`tests/integration/`)

#### Projets Externes (`test_external_projects.py`)
- Tests sur projets simulÃ©s de diffÃ©rentes tailles
- Validation des mÃ©triques collectÃ©es
- Tests d'export sur projets externes
- Mesures de performance
- Gestion d'erreurs avec projets invalides
- Simulation de projets du monde rÃ©el

#### Validation des Outputs (`test_output_validation.py`)
- Validation JSON, Markdown, HTML, CSV
- CohÃ©rence entre tous les formats
- Tests d'encodage UTF-8
- Tests avec caractÃ¨res spÃ©ciaux
- Validation des permissions de fichiers
- Tests avec projets vides

### 3. **Tests de Performance** (`tests/performance/`)

#### MÃ©triques de Performance (`test_performance_metrics.py`)
- Tests sur projets de diffÃ©rentes tailles :
  - **Petit** : 10-50 fichiers (< 1 seconde)
  - **Moyen** : 100-500 fichiers (< 3 secondes)
  - **Grand** : 1000+ fichiers (< 10 secondes)
- Mesures d'utilisation mÃ©moire
- Tests de collecte concurrente
- Benchmarks de vitesse
- Tests de stress avec collecte rÃ©pÃ©tÃ©e

## ğŸš€ **ExÃ©cution des Tests**

### Tests Complets
```bash
# Tous les tests
pytest tests/ -v

# Tests par catÃ©gorie
pytest tests/unit/ -v          # Tests unitaires
pytest tests/integration/ -v   # Tests d'intÃ©gration
pytest tests/performance/ -v   # Tests de performance
```

### Tests SpÃ©cifiques
```bash
# Tests CLI uniquement
pytest tests/unit/cli/ -v

# Tests sur projets externes
pytest tests/integration/test_external_projects.py -v

# Tests de performance
pytest tests/performance/ -v --tb=short
```

### Tests avec Couverture
```bash
# Couverture complÃ¨te
pytest tests/ --cov=src/arkalia_metrics_collector --cov-report=html

# Couverture par module
pytest tests/ --cov=src/arkalia_metrics_collector.collectors --cov-report=term
```

## ğŸ“ˆ **MÃ©triques de QualitÃ©**

### Couverture de Code
- **Collecteurs** : 100% des lignes testÃ©es
- **Exporteurs** : 100% des lignes testÃ©es
- **Validateurs** : 100% des lignes testÃ©es
- **CLI** : 100% des lignes testÃ©es

### Performance
- **Collecte** : < 10 secondes pour 1000+ fichiers
- **Export** : < 5 secondes pour tous les formats
- **Validation** : < 1 seconde pour gros datasets
- **MÃ©moire** : < 200 MB pour projets volumineux

### FiabilitÃ©
- **110/110 tests** passent (100% de rÃ©ussite)
- **0 erreur** de linting (ruff, black, mypy)
- **0 vulnÃ©rabilitÃ©** de sÃ©curitÃ© (bandit)
- **Tests robustes** avec gestion d'erreurs

## ğŸ”§ **Configuration des Tests**

### Variables d'Environnement
```bash
# Mode verbeux
export PYTEST_VERBOSE=1

# Tests de performance uniquement
export PYTEST_PERFORMANCE=1

# Dossier de sortie pour tests
export TEST_OUTPUT_DIR=/tmp/arkalia_tests
```

### Fichiers de Configuration
- `pyproject.toml` : Configuration pytest
- `conftest.py` : Fixtures partagÃ©es
- `pytest.ini` : Options pytest (si nÃ©cessaire)

## ğŸ› **DÃ©bogage des Tests**

### Mode DÃ©bogage
```bash
# ArrÃªt sur premier Ã©chec
pytest tests/ -x

# Mode interactif
pytest tests/ --pdb

# Affichage des prints
pytest tests/ -s
```

### Logs DÃ©taillÃ©s
```bash
# Logs de collecte
pytest tests/ --log-cli-level=DEBUG

# Logs spÃ©cifiques
pytest tests/ --log-cli-level=INFO --log-cli-format="%(asctime)s [%(levelname)8s] %(message)s"
```

## ğŸ“ **Ã‰criture de Nouveaux Tests**

### Structure RecommandÃ©e
```python
def test_nouvelle_fonctionnalite():
    """Test de la nouvelle fonctionnalitÃ©."""
    # Arrange
    input_data = "donnÃ©es de test"
    expected_output = "rÃ©sultat attendu"
    
    # Act
    result = ma_fonction(input_data)
    
    # Assert
    assert result == expected_output
    assert isinstance(result, str)
```

### Fixtures Disponibles
- `temp_project_dir` : Dossier de projet temporaire
- `sample_metrics_data` : DonnÃ©es de mÃ©triques d'exemple
- `runner` : Runner Click pour tests CLI
- `comprehensive_project` : Projet complet pour tests

### Bonnes Pratiques
1. **Noms descriptifs** : `test_collect_metrics_with_large_project`
2. **Documentation** : Docstring explicative
3. **Isolation** : Chaque test est indÃ©pendant
4. **Nettoyage** : Suppression des fichiers temporaires
5. **Assertions claires** : Messages d'erreur explicites

## ğŸš¨ **Tests en CI/CD**

### GitHub Actions
Les tests s'exÃ©cutent automatiquement sur :
- **Python 3.8, 3.9, 3.10, 3.11**
- **Ubuntu, macOS, Windows**
- **Chaque push et PR**

### Validation QualitÃ©
- **Ruff** : Linting et formatage
- **Black** : Formatage automatique
- **MyPy** : VÃ©rification des types
- **Bandit** : SÃ©curitÃ©
- **Pytest** : Tests unitaires et intÃ©gration

## ğŸ“Š **Rapports de Tests**

### Rapport HTML
```bash
pytest tests/ --html=reports/test_report.html --self-contained-html
```

### Rapport JUnit
```bash
pytest tests/ --junitxml=reports/junit.xml
```

### Rapport de Couverture
```bash
pytest tests/ --cov=src/ --cov-report=html --cov-report=term
```

## ğŸ¯ **Prochaines Ã‰tapes**

1. **Tests E2E** : Tests complets bout en bout
2. **Tests de Charge** : Performance sous charge
3. **Tests de CompatibilitÃ©** : DiffÃ©rentes versions Python
4. **Tests de SÃ©curitÃ©** : Validation des entrÃ©es malveillantes

---

**ğŸš€ [Retour Ã  la documentation](../index.md) | ğŸ“ [Voir les tests sur GitHub](https://github.com/arkalia-luna-system/arkalia-metrics-collector/tree/main/tests)**
